{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f848fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Camara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet,SGDRegressor\n",
    "from sklearn.svm import LinearSVR,SVR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textract\n",
    "import os\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import wordninja\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer,LancasterStemmer\n",
    "from pyresparser import ResumeParser\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dd6302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test_ID_files = test['CandidateID']\n",
    "train = pd.read_csv('train.csv')\n",
    "train_ID_files = train['CandidateID']\n",
    "train_percentage = train['Match Percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a436b024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0     candidate_011\n",
       " 1     candidate_113\n",
       " 2     candidate_123\n",
       " 3     candidate_012\n",
       " 4     candidate_002\n",
       "           ...      \n",
       " 85    candidate_133\n",
       " 86    candidate_137\n",
       " 87    candidate_072\n",
       " 88    candidate_140\n",
       " 89    candidate_037\n",
       " Name: CandidateID, Length: 90, dtype: object,\n",
       " 0     13.60\n",
       " 1     36.63\n",
       " 2     54.93\n",
       " 3     41.46\n",
       " 4     48.91\n",
       "       ...  \n",
       " 85    54.20\n",
       " 86    60.18\n",
       " 87    44.94\n",
       " 88    11.41\n",
       " 89    56.70\n",
       " Name: Match Percentage, Length: 90, dtype: float64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_ID_files,train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c972f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47c5ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_train_pdf_files(train_ID_files, train_percentage):\n",
    "    #get english stopwords from stopwords library\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    conv_list = []\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    mat = []\n",
    "    resumes = []\n",
    "    ids = []\n",
    "    percentages = []\n",
    "    strs = []\n",
    "    dirs = os.getcwd()\n",
    "    \n",
    "    for filename in os.listdir(dirs):\n",
    "        if filename == \"trainResumes\":\n",
    "            for file,percentage in zip(train_ID_files,train_percentage):\n",
    "                #candidate_011\n",
    "                #13.6\n",
    "                fullname = f'trainResumes/{file}.pdf'\n",
    "                fullname = os.path.join(dirs, fullname)\n",
    "               \n",
    "                text_extracted = textract.process(fullname)\n",
    "                text_extracted = text_extracted.decode()\n",
    "                text_extracted = text_extracted.strip(\"\\r\\n\")\n",
    "                \n",
    "                for el in text_extracted:\n",
    "                    conv_list.append(el.strip())\n",
    "                    \n",
    "               # print(conv_list)\n",
    "                str_list = \"\".join(conv_list)\n",
    "                #print(str_list)\n",
    "                word_split = wordninja.split(str_list)\n",
    "                #print('word_ninja_split : \\n',word_ninja_split)\n",
    "                \n",
    "                full_description = \" \".join(word_split)\n",
    "                full_description = full_description.lower()\n",
    "                full_description = \" \".join([word for word in full_description.split() if word not in stopWords])\n",
    "                #print(full_description)\n",
    "                \n",
    "                text_encoded = full_description.encode(encoding='ascii',errors='ignore')\n",
    "                #print(text_encoded)\n",
    "                text_decoded = text_encoded.decode()\n",
    "                print(text_decoded)\n",
    "                clean_text = \" \".join([word for word in text_decoded.split()])\n",
    "                text = re.sub(\"@\\S+\", \"\", clean_text)\n",
    "                text = re.sub(\"\\$\", \"\", text)\n",
    "                text = re.sub(\"https?:\\/\\/.*[\\r\\n]*\", \"\", text)\n",
    "                text = re.sub(\"#\", \"\", text)\n",
    "                punct = set(string.punctuation)\n",
    "                text = \"\".join([ch for ch in text if ch not in punct])\n",
    "                words = text.split(\" \")\n",
    "                texts = []\n",
    "                \n",
    "                for word in words:\n",
    "                    texts.append(stemmer.stem(word))\n",
    "                \n",
    "                resumes.append(\" \".join(texts))\n",
    "                ids.append(file)\n",
    "                percentages.append(percentage)\n",
    "                return\n",
    "            return ids,resumes,percentages\n",
    "        #elif filename == \"testResumes\"\n",
    "                \n",
    "            \n",
    "        \n",
    "    return ids,resumes,percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c526a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liam andrews fresher executive summary fresher strong statistical analytic capabilities someone driven passion problem solving though iam civil engineering background always fascinated data machine learning evolving personal skills data analyst data mining data visualization machine learning linear regression statistical modeling predictive modeling sql server oracle python projects railway signals determiner using relay weight system extra curricular data preprocessing python data visualization power bi work experienced ict intern trainee jan 2020 apr 2020 responsible performing helping decision making academic profile b tech civil garo dia institute techno sciences 2020\n"
     ]
    }
   ],
   "source": [
    "read_train_pdf_files(train_ID_files, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6835144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L', 'I', 'A', 'M', '', 'A', 'N', 'D', 'R', 'E', 'W', 'S', '', '', 'F', 'R', 'E', 'S', 'H', 'E', 'R', '', '', '', '', 'E', 'X', 'E', 'C', 'U', 'T', 'I', 'V', 'E', '', 'S', 'U', 'M', 'M', 'A', 'R', 'Y', '', '', 'F', 'r', 'e', 's', 'h', 'e', 'r', '', 'w', 'i', 't', 'h', '', 's', 't', 'r', 'o', 'n', 'g', '', 's', 't', 'a', 't', 'i', 's', 't', 'i', 'c', 'a', 'l', '', 'a', 'n', 'd', '', 'a', 'n', 'a', 'l', 'y', 't', 'i', 'c', '', 'c', 'a', 'p', 'a', 'b', 'i', 'l', 'i', 't', 'i', 'e', 's', '.', '', 'S', 'o', 'm', 'e', 'o', 'n', 'e', '', 'w', 'h', 'o', '', 'i', 's', '', 'd', 'r', 'i', 'v', 'e', 'n', '', 'b', 'y', '', 't', 'h', 'e', '', 'p', 'a', 's', 's', 'i', 'o', 'n', '', 'f', 'o', 'r', '', 'p', 'r', 'o', 'b', 'l', 'e', 'm', '', 's', 'o', 'l', 'v', 'i', 'n', 'g', '.', '', 'T', 'h', 'o', 'u', 'g', 'h', '', 'I', '', 'a', 'm', '', 'f', 'r', 'o', 'm', '', 'C', 'i', 'v', 'i', 'l', '', 'E', 'n', 'g', 'i', 'n', 'e', 'e', 'r', 'i', 'n', 'g', '', 'b', 'a', 'c', 'k', 'g', 'r', 'o', 'u', 'n', 'd', '', 'I', '', 'h', 'a', 'v', 'e', '', 'a', 'l', 'w', 'a', 'y', 's', '', 'b', 'e', 'e', 'n', '', 'f', 'a', 's', 'c', 'i', 'n', 'a', 't', 'e', 'd', '', 'w', 'i', 't', 'h', '', 'd', 'a', 't', 'a', '', 'a', 'n', 'd', '', 'h', 'o', 'w', '', 'M', 'a', 'c', 'h', 'i', 'n', 'e', '', 'L', 'e', 'a', 'r', 'n', 'i', 'n', 'g', '', 'i', 's', '', 'e', 'v', 'o', 'l', 'v', 'i', 'n', 'g', '', 'w', 'i', 't', 'h', '', 'i', 'i', 't', '.', '', '', 'P', 'E', 'R', 'S', 'O', 'N', 'A', 'L', '', 'S', 'K', 'I', 'L', 'L', 'S', '', '', 'D', 'a', 't', 'a', '', 'A', 'n', 'a', 'l', 'y', 's', 't', ',', '', 'D', 'a', 't', 'a', '', 'M', 'i', 'n', 'i', 'n', 'g', ',', '', 'D', 'a', 't', 'a', '', 'V', 'i', 's', 'u', 'a', 'l', 'i', 'z', 'a', 't', 'i', 'o', 'n', ',', '', 'M', 'a', 'c', 'h', 'i', 'n', 'e', '', 'L', 'e', 'a', 'r', 'n', 'i', 'n', 'g', ',', '', 'L', 'i', 'n', 'e', 'a', 'r', '', 'R', 'e', 'g', 'r', 'e', 's', 's', 'i', 'o', 'n', ',', '', 'S', 't', 'a', 't', 'i', 's', 't', 'i', 'c', 'a', 'l', '', 'M', 'o', 'd', 'e', 'l', 'i', 'n', 'g', ',', '', 'P', 'r', 'e', 'd', 'i', 'c', 't', 'i', 'v', 'e', '', 'M', 'o', 'd', 'e', 'l', 'i', 'n', 'g', ',', '', 'S', 'Q', 'L', '', 'S', 'e', 'r', 'v', 'e', 'r', ',', '', 'O', 'r', 'a', 'c', 'l', 'e', ',', '', 'P', 'y', 't', 'h', 'o', 'n', '.', '', '', 'P', 'R', 'O', 'J', 'E', 'C', 'T', 'S', '', '', 'R', 'a', 'i', 'l', 'w', 'a', 'y', '', 'S', 'i', 'g', 'n', 'a', 'l', 's', '', 'D', 'e', 't', 'e', 'r', 'm', 'i', 'n', 'e', 'r', '', 'u', 's', 'i', 'n', 'g', '', 'r', 'e', 'l', 'a', 'y', '', 'w', 'e', 'i', 'g', 'h', 't', '', 's', 'y', 's', 't', 'e', 'm', '.', '', '', 'E', 'X', 'T', 'R', 'A', '-', 'C', 'U', 'R', 'R', 'I', 'C', 'U', 'L', 'A', 'R', 'S', '', '', 'D', 'a', 't', 'a', '', 'P', 'r', 'e', 'p', 'r', 'o', 'c', 'e', 's', 's', 'i', 'n', 'g', '', 'w', 'i', 't', 'h', '', 'P', 'y', 't', 'h', 'o', 'n', '', 'D', 'a', 't', 'a', '', 'V', 'i', 's', 'u', 'a', 'l', 'i', 'z', 'a', 't', 'i', 'o', 'n', '', 'w', 'i', 't', 'h', '', 'P', 'o', 'w', 'e', 'r', '', 'B', 'I', '', '', '', '', 'W', 'O', 'R', 'K', '', 'E', 'X', 'P', 'E', 'R', 'I', 'E', 'N', 'C', 'E', '', '', 'D', 'I', 'C', 'T', 'I', 'S', '', '', 'I', 'n', 't', 'e', 'r', 'n', '', 'T', 'r', 'a', 'i', 'n', 'e', 'e', ',', '', 'J', 'a', 'n', '', '2', '0', '2', '0', '', 't', 'o', '', 'A', 'p', 'r', '', '2', '0', '2', '0', '', 'R', 'e', 's', 'p', 'o', 'n', 's', 'i', 'b', 'l', 'e', '', 'f', 'o', 'r', '', 'p', 'e', 'r', 'f', 'o', 'r', 'm', 'i', 'n', 'g', '', 'a', 'n', 'd', '', 'h', 'e', 'l', 'p', 'i', 'n', 'g', '', 'i', 'n', '', 'd', 'e', 'c', 'i', 's', 'i', 'o', 'n', '', 'm', 'a', 'k', 'i', 'n', 'g', '.', '', '', 'A', 'C', 'A', 'D', 'E', 'M', 'I', 'C', '', 'P', 'R', 'O', 'F', 'I', 'L', 'E', '', '', 'B', '.', 'T', 'e', 'c', 'h', '(', 'C', 'i', 'v', 'i', 'l', ')', '', 'G', 'a', 'r', 'o', 'd', 'i', 'a', '', 'I', 'n', 's', 't', 'i', 't', 'u', 't', 'e', '', 'o', 'f', '', 'T', 'e', 'c', 'h', 'n', 'o', 's', 'c', 'i', 'e', 'n', 'c', 'e', 's', ',', '', '2', '0', '2', '0', '', '', '', '', '']\n",
      "LIAMANDREWSFRESHEREXECUTIVESUMMARYFresherwithstrongstatisticalandanalyticcapabilities.Someonewhoisdrivenbythepassionforproblemsolving.ThoughIamfromCivilEngineeringbackgroundIhavealwaysbeenfascinatedwithdataandhowMachineLearningisevolvingwithiit.PERSONALSKILLSDataAnalyst,DataMining,DataVisualization,MachineLearning,LinearRegression,StatisticalModeling,PredictiveModeling,SQLServer,Oracle,Python.PROJECTSRailwaySignalsDeterminerusingrelayweightsystem.EXTRA-CURRICULARSDataPreprocessingwithPythonDataVisualizationwithPowerBIWORKEXPERIENCEDICTISInternTrainee,Jan2020toApr2020Responsibleforperformingandhelpingindecisionmaking.ACADEMICPROFILEB.Tech(Civil)GarodiaInstituteofTechnosciences,2020\n",
      "word_ninja_split : \n",
      " ['LIAM', 'ANDREWS', 'FRESHER', 'EXECUTIVE', 'SUMMARY', 'Fresher', 'with', 'strong', 'statistical', 'and', 'analytic', 'capabilities', 'Someone', 'who', 'is', 'driven', 'by', 'the', 'passion', 'for', 'problem', 'solving', 'Though', 'Iam', 'from', 'Civil', 'Engineering', 'background', 'I', 'have', 'always', 'been', 'fascinated', 'with', 'data', 'and', 'how', 'Machine', 'Learning', 'is', 'evolving', 'with', 'i', 'it', 'PERSONAL', 'SKILLS', 'Data', 'Analyst', 'Data', 'Mining', 'Data', 'Visualization', 'Machine', 'Learning', 'Linear', 'Regression', 'Statistical', 'Modeling', 'Predictive', 'Modeling', 'SQL', 'Server', 'Oracle', 'Python', 'PROJECTS', 'Railway', 'Signals', 'Determiner', 'using', 'relay', 'weight', 'system', 'EXTRA', 'CURRICULAR', 'S', 'Data', 'Preprocessing', 'with', 'Python', 'Data', 'Visualization', 'with', 'Power', 'BI', 'WORK', 'EXPERIENCED', 'ICT', 'IS', 'Intern', 'Trainee', 'Jan', '2020', 'to', 'Apr', '2020', 'Responsible', 'for', 'performing', 'and', 'helping', 'in', 'decision', 'making', 'ACADEMIC', 'PROFILE', 'B', 'Tech', 'Civil', 'Garo', 'dia', 'Institute', 'of', 'Techno', 'sciences', '2020']\n"
     ]
    }
   ],
   "source": [
    "read_train_pdf_files(train_ID_files, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48eab30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LIAM ANDREWS\r\n",
      "FRESHER\r\n",
      "\r\n",
      "EXECUTIVE SUMMARY\r\n",
      "Fresher with strong statistical and analytic capabilities. Someone who is driven by the passion for problem solving. Though I am from Civil Engineering background I have always been fascinated with data and how Machine Learning is evolving with iit.\r\n",
      "PERSONAL SKILLS\r\n",
      "Data Analyst, Data Mining, Data Visualization, Machine Learning, Linear Regression, Statistical Modeling, Predictive Modeling, SQL Server, Oracle, Python.\r\n",
      "PROJECTS\r\n",
      "Railway Signals Determiner using relay weight system.\r\n",
      "EXTRA-CURRICULARS\r\n",
      "Data Preprocessing with Python Data Visualization with Power BI\r\n",
      "\r\n",
      "WORK EXPERIENCE\r\n",
      "DICTIS\r\n",
      "Intern Trainee, Jan 2020 to Apr 2020 Responsible for performing and helping in decision making.\r\n",
      "ACADEMIC PROFILE\r\n",
      "B.Tech(Civil) Garodia Institute of Technosciences, 2020\r\n",
      "\r\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "read_train_pdf_files(train_ID_files, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027b3813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "b'LIAM ANDREWS\\r\\nFRESHER\\r\\n\\r\\nEXECUTIVE SUMMARY\\r\\nFresher with strong statistical and analytic capabilities. Someone who is driven by the passion for problem solving. Though I am from Civil Engineering background I have always been fascinated with data and how Machine Learning is evolving with iit.\\r\\nPERSONAL SKILLS\\r\\nData Analyst, Data Mining, Data Visualization, Machine Learning, Linear Regression, Statistical Modeling, Predictive Modeling, SQL Server, Oracle, Python.\\r\\nPROJECTS\\r\\nRailway Signals Determiner using relay weight system.\\r\\nEXTRA-CURRICULARS\\r\\nData Preprocessing with Python Data Visualization with Power BI\\r\\n\\r\\nWORK EXPERIENCE\\r\\nDICTIS\\r\\nIntern Trainee, Jan 2020 to Apr 2020 Responsible for performing and helping in decision making.\\r\\nACADEMIC PROFILE\\r\\nB.Tech(Civil) Garodia Institute of Technosciences, 2020\\r\\n\\r\\n\\x0c'\n"
     ]
    }
   ],
   "source": [
    "read_train_pdf_files(train_ID_files, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3db68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
